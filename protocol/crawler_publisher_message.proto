syntax = "proto3";
package protocol;

import "google/protobuf/timestamp.proto";

option go_package = "github.com/Luismorlan/newsmux/publisher/protocol";

// To regenerate go file:
// protoc --go_out=. --go_opt=paths=source_relative ./protocol/crawler_publisher_message.proto --experimental_allow_proto3_optional

// To regenerate python file:
// protoc -I=./protocol --python_out=./protocol ./protocol/crawler_publisher_message.proto

// A CrawlerMessage represent a post generated by crawler
// Used to communicate between crawler and publisher
message CrawlerMessage {

  message CrawledPost {
    // Original post id that associated with this post in the crawled website.
    // This is for deduplication purpose both in SNS and in Publisher, to make
    // sure we're not inserting the same post twice.
    string post_id = 1;

    // source_id is the sources id generated in DB, in table "sources"
    // for a crawler, when it starts crawl, it should read DB first
    // and when crawler sends message, each message should have source_id
    // and sub_source_id
    string source_id = 2;

    // sub_source_id is the sub_source id generated in DB, in table "sub_sources"
    string sub_source_id = 3;

    // title is the title of the post
    string title = 4;

    // content is the plain text content of the post
    string content = 5;

    // image_urls stores urls to images attached to the post
    repeated string image_urls = 6;

    // files_urls stores urls to files attached to the post
    repeated string files_urls = 7;

    // content_generated_at is the actual time content is generated by 3rd party website
    google.protobuf.Timestamp content_generated_at = 8;

    // origin_url is the url of crawled website
    // example: "http://companies.caixin.com/2021-04-10/101688620.html"
    string origin_url = 9;
  }

  // The post details that this message sends
  CrawledPost post = 1;

  // Other auxiliary fields describing the cralwer and message status, regardless of post

  // crawled_at is the time stamp when crawler generate the post
  // note this is different from the actual time content is generated by 3rd party website
  google.protobuf.Timestamp crawled_at = 2;

  // crawler_ip is the crawler's ip to identify which host/lambda generated the post
  string crawler_ip = 3;

  // crawler_version is the crawler's version, this is place holder in future if we want to do AB test
  string crawler_version = 4;

  // is_test is to mark if the post is for end-to-end test purpose
  bool is_test = 5;
}
