syntax = "proto3";
package protocol;

import "google/protobuf/timestamp.proto";

option go_package = "github.com/Luismorlan/newsmux/publisher/protocol";

// To regenerate go file:
// protoc --go_out=. --go_opt=paths=source_relative ./protocol/crawler_publisher_message.proto --experimental_allow_proto3_optional

// A CrawlerMessage represent a post generated by crawler
// Used to communicate between crawler and publisher
message CrawlerMessage {
  // source_id is the sources id generated in DB, in table "sources"
  // for a crawler, when it starts crawl, it should read DB first
  // and when crawler sends message, each message should have source_id
  // and sub_source_id
  string source_id = 1;

  // sub_source_id is the sub_source id generated in DB, in table "sub_sources"
  string sub_source_id = 2;

  // title is the title of the post
  string title = 3;

  // content is the plain text content of the post
  string content = 4;

  // image_urls stores urls to images attached to the post
  repeated string image_urls = 5;

  // files_urls stores urls to files attached to the post
  repeated string files_urls = 6;

  // crawled_at is the time stamp when crawler generate the post
  // note this is different from the actual time content is generated by 3rd party website
  google.protobuf.Timestamp crawled_at = 7;

  // origin_url is the url of crawled website
  // example: "http://companies.caixin.com/2021-04-10/101688620.html"
  string origin_url = 8;

  // crawler_ip is the crawler's ip to identify which host/lambda generated the post
  string crawler_ip = 9;

  // crawler_version is the crawler's version, this is place holder in future if we want to do AB test
  string crawler_version = 10;

  // is_test is to mark if the post is for end-to-end test purpose
  bool is_test = 11;

  // content_generated_at is the actual time content is generated by 3rd party website
  google.protobuf.Timestamp content_generated_at = 12;
}
