package model

import (
	"time"

	"github.com/lib/pq"
	"gorm.io/gorm"
)

/*

Post is a piece of news crawler fetched

Id: primary key, use to identify a sub-source
CreatedAt: time when entity is created
DeletedAt: time when entity is deleted

Title: post's title in plain text
Content: post's content in plain text
SourceID:
Source: source website for example "twitter", "weibo", "Caixin",  "belongs-to" relation
SubSourceID:
SubSource: for example a twitter user, weibo user, sub channel in Caixin etc., "belongs-to" relation

SharedFromPostID:
SharedFromPost:
		if the post is a user shared(like re-twitt) post, set this as the Post originally shared. Support multi-level sharing.
		also if the post is shared:
			Source is a FAKE one representing "shared".
				Name is "分享"
			SubSource representing "user".
				CreatorID is user_id
				Creator is User
				Name is user's name
				ExternalIdentifier is empty


SavedByUser: mark when user save the post, "many-to-many" relation
PublishedFeeds: feeds that this post published to, "many-to-many" relation

Cursor: The auto-inc global-unique index to keep the relative order of posts

ImageUrlsInJson: Urls for the attached images, in json format string

FileUrlsInJson: Urls for the attached files, in json format string

CrawledAt: The time stamp when crawler generate the post

OriginUrl: The origin_url is the url of crawled website example: "http://companies.caixin.com/2021-04-10/101688620.html"

ContentGeneratedAt: The actual time content is generated by 3rd party website

InSharingChain: If this post is some other post retweets.
	the in-chain posts will not be published as an independent post in a feed, however,
	however, its content will be used to publish/match its root post in the chain.

DeduplicateId: A hash to deduplicate across posts, generated by crawler

SemanticHashing: A hash with the property that similar content will be hashed
into near neighbor in Hamming space. It is a 128 bit binary string.
*/

type Post struct {
	Id                 string `gorm:"primaryKey"`
	CreatedAt          time.Time
	DeletedAt          gorm.DeletedAt
	Title              string
	Content            string
	SubSourceID        string    `gorm:"constraint:OnUpdate:CASCADE,OnDelete:SET NULL;"`
	SubSource          SubSource `gorm:"constraint:OnUpdate:CASCADE,OnDelete:SET NULL;"`
	SharedFromPostID   *string
	SharedFromPost     *Post
	SavedByUser        []*User `json:"saved_by_user" gorm:"many2many;"`
	PublishedFeeds     []*Feed `json:"published_feeds" gorm:"many2many:post_feed_publishes;constraint:OnDelete:CASCADE;"`
	Cursor             int32   `gorm:"autoIncrement"`
	CrawledAt          time.Time
	OriginUrl          string
	ContentGeneratedAt time.Time
	InSharingChain     bool

	// TODO: convert json to array when serve graphql API and ingest from crawler
	ImageUrls pq.StringArray `gorm:"type:TEXT[]"`
	FileUrls  pq.StringArray `gorm:"type:TEXT[]"`

	DeduplicateId   string
	SemanticHashing string
	Tag             string
}
